{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "TRAIN_PATH ='WSJ_02-21.pos' \n",
    "X_TEST_PATH ='WSJ_24.words'\n",
    "Y_TEST_PATH = 'WSJ_24.pos' \n",
    "TEST_PATH = 'WSJ_23.words'\n",
    "word_set = set()\n",
    "tag_set = set()\n",
    "len_word_set = set()\n",
    "len_tag_set = set()\n",
    "tag_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and convert training corpus in list(tuple(word, tag))\n",
    "total = []\n",
    "per_pos = {}\n",
    "with open(TRAIN_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line.split()) != 0:\n",
    "            token = line.split()\n",
    "            total.append((token[0], token[1]))\n",
    "            if token[1] not in per_pos:\n",
    "                per_pos[token[1]] = [token]\n",
    "            else:\n",
    "                per_pos[token[1]].append(token)\n",
    "word_set = set([x[0] for x in total]) \n",
    "tag_set = set([x[1] for x in total])\n",
    "len_word_set = len(word_set)\n",
    "len_tag_set = len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('an', 'DT'), ('Oct.', 'NNP'), ('19', 'CD'), ('review', 'NN'), ('of', 'IN'), ('``', '``'), ('The', 'DT'), ('Misanthrope', 'NN'), (\"''\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "print(total[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line.split()) != 0:\n",
    "            broken = line.split()\n",
    "            if broken[1] not in tag_count:\n",
    "                tag_count[broken[1]] = 1\n",
    "            else:\n",
    "                tag_count[broken[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN': 98554,\n",
       " 'DT': 81842,\n",
       " 'NNP': 91466,\n",
       " 'CD': 36568,\n",
       " 'NN': 132935,\n",
       " '``': 7092,\n",
       " \"''\": 6919,\n",
       " 'POS': 8701,\n",
       " '(': 1366,\n",
       " 'VBN': 20024,\n",
       " 'NNS': 59856,\n",
       " 'VBP': 12491,\n",
       " ',': 48727,\n",
       " 'CC': 23947,\n",
       " ')': 1376,\n",
       " 'VBD': 29889,\n",
       " 'RB': 30970,\n",
       " 'TO': 22357,\n",
       " '.': 39478,\n",
       " 'VBZ': 21672,\n",
       " 'NNPS': 2673,\n",
       " 'PRP': 17436,\n",
       " 'PRP$': 8407,\n",
       " 'VB': 26438,\n",
       " 'JJ': 61217,\n",
       " 'MD': 9803,\n",
       " 'VBG': 14846,\n",
       " 'RBR': 1768,\n",
       " ':': 4772,\n",
       " 'WP': 2363,\n",
       " 'WDT': 4294,\n",
       " 'JJR': 3238,\n",
       " 'PDT': 370,\n",
       " 'RBS': 451,\n",
       " 'WRB': 2143,\n",
       " 'JJS': 1947,\n",
       " '$': 7372,\n",
       " 'RP': 2662,\n",
       " 'FW': 234,\n",
       " 'EX': 863,\n",
       " 'SYM': 58,\n",
       " '#': 142,\n",
       " 'LS': 36,\n",
       " 'UH': 97,\n",
       " 'WP$': 168}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab and convert x_test -> (words,)\n",
    "x_test = []\n",
    "with open(X_TEST_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line.split()) != 0:\n",
    "            token = line.split()\n",
    "            x_test.append(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', 'vantage']\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab test answers (words, pos)\n",
    "y_test = []\n",
    "with open(Y_TEST_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        token = line.split()\n",
    "        if len(token) != 0:\n",
    "            y_test.append((token[0], token[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('economy', 'NN'), (\"'s\", 'POS'), ('temperature', 'NN'), ('will', 'MD'), ('be', 'VB'), ('taken', 'VBN'), ('from', 'IN'), ('several', 'JJ'), ('vantage', 'NN')]\n",
      "32853\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10])\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "with open(TEST_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        if len(line.split()) != 0:\n",
    "            test.append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', ',', 'it', 'was', \"n't\", 'Black', 'Monday', '.', 'But', 'while']\n"
     ]
    }
   ],
   "source": [
    "print(test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_w_given_t(word, tag, train_bag = total, per_pos = per_pos):\n",
    "    tag_list = per_pos[tag]\n",
    "    tag_count = len(tag_list)\n",
    "    p_w_given_t_list = [pair[0] for pair in tag_list if pair[0] == word]\n",
    "    p_w_given_t_count = len(p_w_given_t_list)\n",
    "    return (p_w_given_t_count, tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_probabilties(curr, prev, train_bag = total):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    prev_tags_list = [tag for tag in tags if tag == prev]\n",
    "    prev_tags_count = len(prev_tags_list)\n",
    "    curr_given_prev_list = [tags[index+1] for index in range(len(tags) - 1) if tags[index] == prev and tags[index+1] == curr]\n",
    "    curr_given_prev_count = len(curr_given_prev_list)\n",
    "    return (curr_given_prev_count, prev_tags_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition matrix\n",
    "transition_matrix = np.zeros((len_tag_set,len_tag_set), dtype = 'float32')\n",
    "for i, prev in enumerate(list(tag_set)):\n",
    "    for j, curr in enumerate(list(tag_set)):\n",
    "        transition_matrix[i,j] = transition_probabilties(curr, prev)[0] /  transition_probabilties(curr, prev)[1]\n",
    "df_transition = pd.DataFrame(transition_matrix, columns = list(tag_set), index = list(tag_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df = df_transition,test = x_test, train_bag = total, tag_set = tag_set):\n",
    "        state = []\n",
    "        T = list(tag_set)\n",
    "        for k, w in enumerate(test):\n",
    "            if k % 100 == 0: print('Predict Progress: ', k/len(test))\n",
    "            p= []\n",
    "            p_transition = []\n",
    "            for tag in T:\n",
    "                if k == 0:\n",
    "                    transition_p = df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = df.loc[state[-1], tag]\n",
    "                emission_p = p_w_given_t(test[k], tag)[0] / p_w_given_t(test[k], tag)[1]\n",
    "                state_probability = emission_p * transition_p\n",
    "                p.append(state_probability)\n",
    "                p_transition.append(transition_p)\n",
    "            pmax = max(p)\n",
    "            state_max = T[p.index(pmax)]\n",
    "            # OOV handling : possibility 1 from slides -> only using transition probability\n",
    "            if (pmax == 0):\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]\n",
    "            else:\n",
    "                state_max = T[p.index(pmax)]\n",
    "            state.append(state_max)\n",
    "        return list(zip(test, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on X_train and Y_train/Y_test\n",
    "res = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score (keyFileName, responseFileName):\n",
    "    keyFile = open(keyFileName, 'r')\n",
    "    key = keyFile.readlines()\n",
    "    responseFile = open(responseFileName, 'r')\n",
    "    response = responseFile.readlines()\n",
    "    if len(key) != len(response):\n",
    "        print(\"length mismatch between key and submitted file of: \", len(keyFileName) - len(responseFileName))\n",
    "        exit()\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(key)):\n",
    "        key[i] = key[i].rstrip(os.linesep)\n",
    "        response[i] = response[i].rstrip(os.linesep)\n",
    "        if key[i] == \"\":\n",
    "            if response[i] == \"\":\n",
    "                continue\n",
    "            else:\n",
    "                print (\"sentence break expected at line \" + str(i))\n",
    "                exit()\n",
    "        keyFields = key[i].split('\\t')\n",
    "        if len(keyFields) != 2:\n",
    "            print (\"format error in key at line \" + str(i) + \":\" + key[i])\n",
    "            exit()\n",
    "        keyToken = keyFields[0]\n",
    "        keyPos = keyFields[1]\n",
    "        responseFields = response[i].split('\\t')\n",
    "        if len(responseFields) != 2:\n",
    "            print (\"format error at line \" + str(i))\n",
    "            exit()\n",
    "        responseToken = responseFields[0]\n",
    "        responsePos = responseFields[1]\n",
    "        if responseToken != keyToken:\n",
    "            print (\"token mismatch at line \" + str(i))\n",
    "            exit()\n",
    "        if responsePos == keyPos:\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            incorrect = incorrect + 1\n",
    "    print (str(correct) + \" out of \" + str(correct + incorrect) + \" tags correct\")\n",
    "    accuracy = 100.0 * correct / (correct + incorrect)\n",
    "    print(\"  accuracy: %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Algorithm Accuracy:  93.76921437920433\n"
     ]
    }
   ],
   "source": [
    "# accuracy of training data using naive accuracy from declared variables\n",
    "check = [i for i, j in zip(res, y_test) if i == j] \n",
    "accuracy = len(check)/len(res)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out training results to test of score.py format\n",
    "with open('training.txt','w') as outf:\n",
    "    dummy = []\n",
    "    with open(Y_TEST_PATH, 'r') as f:\n",
    "        for line in f:\n",
    "            dummy.append(line.split())\n",
    "        count = 0\n",
    "        for i in range(len(dummy)):\n",
    "            if len(dummy[i]) == 0:\n",
    "                outf.write('\\n')\n",
    "                count += 1\n",
    "            else:\n",
    "                if dummy[i][1] == '.':\n",
    "                    outf.write(res[i-count][0] + '\\t' + res[i-count][1] + '\\n')\n",
    "                else:\n",
    "                    outf.write(res[i-count][0] + '\\t' + res[i-count][1] + '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30806 out of 32853 tags correct\n",
      "  accuracy: 93.769214\n"
     ]
    }
   ],
   "source": [
    "# test accuracy from score.py submission format (Beware extra sentence breaks in keyFile)\n",
    "score(Y_TEST_PATH, 'training.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
